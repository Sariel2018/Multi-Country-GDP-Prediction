{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3da2e-f4f5-4b5f-b11e-07b7307c2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455abe5-334e-4718-9848-d57af05bed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0b527-348f-4c89-82e4-cf7a37292d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timesfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6c7396-8bfa-42ac-bdb3-db642b7bff1e",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380cb52-f5ea-4a04-8ef0-719258d7ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = timesfm.TimesFm(\n",
    "    context_len=512,\n",
    "    horizon_len=1,\n",
    "    input_patch_len=32,\n",
    "    output_patch_len=128,\n",
    "    num_layers=20,\n",
    "    model_dims=1280,\n",
    "    backend=\"gpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb712b-4cf5-495e-aac5-394d078c6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm.load_from_checkpoint(checkpoint_path=\"~/timesfm-1.0-200m/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fb63d-9496-412c-8603-a6d2d5de77c5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f40b9-497f-46f5-99ae-1885dcafde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60db5b-8690-4b55-9b94-57fe1d8158b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 如果你使用多个GPU\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7cf18-9422-4e71-a641-2608db1dd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算最小值和最大值, 并进行归一化\n",
    "def norm_lstm_tensor(data, labels, freq='quarter'):\n",
    "    if freq == 'quarter':\n",
    "        drop_index = -3\n",
    "    else:\n",
    "        drop_index = -2\n",
    "    \n",
    "    # 将最后一维的数据分开\n",
    "    data_to_norm = data[:, :, :drop_index]  # 除了最后一个维度\n",
    "    labels_to_norm = labels[:, :drop_index]  # 除了最后一个维度\n",
    "\n",
    "    # 计算data的最小值和最大值\n",
    "    max_vals_data, _ = torch.max(data_to_norm, dim=0)  # 对第一个维度求最大值\n",
    "    max_vals_data, _ = torch.max(max_vals_data, dim=0)  # 再对第二个维度求最大值\n",
    "    \n",
    "    min_vals_data, _ = torch.min(data_to_norm, dim=0)  # 对第一个维度求最小值\n",
    "    min_vals_data, _ = torch.min(min_vals_data, dim=0)  # 再对第二个维度求最小值\n",
    "\n",
    "    # 计算labels的最小值和最大值\n",
    "    min_vals_label = labels_to_norm.min(dim=0, keepdim=True).values[-1]\n",
    "    max_vals_label = labels_to_norm.max(dim=0, keepdim=True).values[-1]\n",
    "\n",
    "    min_value_all = torch.min(min_vals_data, min_vals_label)\n",
    "    max_value_all = torch.max(max_vals_data, max_vals_label)\n",
    "\n",
    "    min_value = min_value_all[-1]\n",
    "    max_value = max_value_all[-1]\n",
    "\n",
    "    # 计算 Min-Max 归一化\n",
    "    # 对 data (去除最后一个维度的部分) 进行 Min-Max 归一化\n",
    "    normalized_data_to_norm = (data_to_norm - min_value_all) / (max_value_all - min_value_all)\n",
    "\n",
    "    # 对 label (去除最后一个维度的部分) 进行 Min-Max 归一化\n",
    "    normalized_labels_to_norm = (labels_to_norm - min_value_all) / (max_value_all - min_value_all)\n",
    "\n",
    "    # 重新拼接保留的最后一个维度\n",
    "    normalized_data = torch.cat([normalized_data_to_norm, data[:, :, drop_index:]], dim=2)\n",
    "    normalized_label = torch.cat([normalized_labels_to_norm, labels[:, drop_index:]], dim=1)\n",
    "    \n",
    "    return normalized_data, normalized_label, min_value, max_value\n",
    "\n",
    "\n",
    "def split_lstm_dataset_by_year(data, labels, year, freq='quarter'):\n",
    "    if freq == 'quarter':\n",
    "        dim_index = -2\n",
    "    else:\n",
    "        dim_index = -1\n",
    "        \n",
    "    train_index_list = []\n",
    "    test_index_list = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i, dim_index] >= year:\n",
    "            test_index_list.append(i)\n",
    "        else:\n",
    "            train_index_list.append(i)\n",
    "\n",
    "\n",
    "    train_data = data[train_index_list, :, :dim_index-1]\n",
    "    train_targets = labels[train_index_list, :dim_index-1]\n",
    "    \n",
    "    test_data = data[test_index_list, :, :dim_index-1]\n",
    "    test_targets = labels[test_index_list, :dim_index-1]\n",
    "    return train_data, test_data, train_targets, test_targets\n",
    "\n",
    "\n",
    "def reverse_norm(row):\n",
    "    # row = row.cpu()\n",
    "    if len(row.shape) == 2:\n",
    "        gap = max_value.item() - min_value.item()\n",
    "        return row[:, -1] * gap + min_value.item()\n",
    "    else:\n",
    "        gap = max_value.item() - min_value.item()\n",
    "        return row * gap + min_value.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4530f43-16bf-413a-b21a-c7f63319a8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750cca0-f026-4078-9143-c548437342b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_item_list = []\n",
    "for file_item in os.listdir('../dataset/'):\n",
    "    if ('LSTM_data_gdp_' in file_item) and ('light' not in file_item):\n",
    "        file_item_list.append(file_item)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print('file item list length: ', len(file_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ace0e-bd95-48ff-853d-ea6cdfb27a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e60d3-33a7-4060-9346-48b8e872373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import metric\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bafcb-4d5d-4f74-a7a0-8f3460637e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "dict_temp = {}\n",
    "for file_item in file_item_list:\n",
    "    print(file_item)\n",
    "    start_time = time.time()\n",
    "    data_path = '../dataset/' + file_item\n",
    "    label_path = '../dataset/' + file_item.replace('LSTM_data', 'LSTM_label')\n",
    "    \n",
    "    \n",
    "    set_seed(1)\n",
    "    data = torch.load(data_path)\n",
    "    labels = torch.load(label_path)\n",
    "    \n",
    "    data, labels, min_value, max_value = norm_lstm_tensor(data, labels, 'quarter')\n",
    "    if '95-19' in file_item:\n",
    "        year = 2018\n",
    "    elif '13-19' in file_item:\n",
    "        year = 2019\n",
    "    else:\n",
    "        raise ValueError('Wrong')\n",
    "    train_data, test_data, train_targets, test_targets = split_lstm_dataset_by_year(data, labels, year, freq='quarter')\n",
    "\n",
    "    forecast_input = test_data[:, :, -1]\n",
    "    frequency_input = [2] * test_data[:, :, -1].shape[0]\n",
    "    \n",
    "    point_forecast, experimental_quantile_forecast = tfm.forecast(\n",
    "        forecast_input,\n",
    "        freq=frequency_input,\n",
    "    )\n",
    "\n",
    "\n",
    "    # mae, mse, rmse, mape, mspe, rse, corr\n",
    "    mae, mse, rmse, mape, mspe, rse, corr = metric(torch.Tensor([reverse_norm(item) for item in test_targets[:, -1]]),\n",
    "          torch.Tensor([reverse_norm(item) for item in point_forecast]))\n",
    "\n",
    "    print('mae, mse, rmse, mape, mspe, rse, corr', mae, mse, rmse, mape, mspe, rse, corr)\n",
    "    dict_temp[file_item] = [mae, mse, rmse, mape, mspe, rse, corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed25f7-191d-4788-b70f-e0635508a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(dict_temp).T\n",
    "df_res.columns = ['mae', 'mse', 'rmse', 'mape', 'mspe', 'rse', 'corr']\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802bc49-005e-4ce0-86da-1ef382ec64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['mae', 'mse', 'rmse', 'mape', 'mspe', 'rse', 'corr']:\n",
    "    df_res[col] = df_res[col].apply(lambda x: x.item())\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842553b6-4974-457d-9af2-0bff2b1357f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('timesfm_lstm_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c25e35-524f-4ac4-a3c3-76341e2365c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c0a8b-bd03-49af-9edf-81d93a4a311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289e83b-7d29-48d9-a014-129dcd78b644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1f4bf-a755-4fa3-bf66-f3102c7046b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3e791-9c10-4566-a90b-05ade1d94d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a150732-2d04-4dfd-843c-1fe9adfa913b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d359ec-fc4f-484a-a16a-e3cdad5e6375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245b9ad-deb7-4063-8c44-b4a7ea65d0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab77f5-560f-4f8f-bcaa-17626601bf96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089369e-0157-481f-beb3-94336266282b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90f011-1621-457b-9611-aa77a9fa7f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
